{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO : introduction / paper address / reference / read.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "\n",
    "Tensorflow must be imported after scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input & Output image Setting\n",
    "<font color='blue'><b> TODO : Edit this to using parser </b></font>\n",
    "\n",
    "<b>[1]</b> Path for images\n",
    "\n",
    "<b>[2]</b> Image dimensions <br>\n",
    "\n",
    "<b>[3]</b> Model - ImageNet VGG-19 <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Normalized model<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(http://bethgelab.org/deepneuralart/)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MEAN_VALUES is value of each RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STYLE_IMAGE = 'images/a.jpg'\n",
    "CONTENT_IMAGE = 'images/b.jpg'\n",
    "\n",
    "IMAGE_WIDTH = 436\n",
    "IMAGE_HEIGHT = 300\n",
    "COLOR_CHANNELS = 3\n",
    "\n",
    "VGG_MODEL = 'imagenet-vgg-verydeep-19.mat'\n",
    "MEAN_VALUES = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter\n",
    "\n",
    "<b>[1]</b> NOISE_RATIO ($\\gamma$) : Constant for initialize <b>white noise image</b> using <b>content image</b>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$Input Image=\\gamma*White Noise + (1-\\gamma)*Content Image$\n",
    "\n",
    "<br>\n",
    "<b>[2]</b> ALPHA & BETA ($\\alpha, \\beta$) : Ratio of <b>content loss</b> and <b>style loss</b> for <b>total loss</b><br>\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\mathcal{L}_{ total}=\\alpha*\\mathcal{L}_{content} + \\beta*\\mathcal{L}_{style}$\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(paper advise $\\alpha/\\beta$ about $10^{-3}$ ~ $10^{-4}$)\n",
    "\n",
    "<br>\n",
    "<b>[3]</b> STYLE_LAYERS & CONTENT_LAYERS : Selected layers from vgg and their weights <br><br>\n",
    "<b>[4]</b> ITERATIONS : Number of iterations to run<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NOISE_RATIO = 0.6\n",
    "\n",
    "ALPHA = 1\n",
    "BETA = 1000\n",
    "\n",
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', 0.3),\n",
    "    ('conv2_1', 0.25),\n",
    "    ('conv3_1', 0.2),\n",
    "    ('conv4_1', 0.15),\n",
    "    ('conv5_1', 0.1),\n",
    "]\n",
    "\n",
    "CONTENT_LAYERS = [\n",
    "    ('conv4_2', 1.0)\n",
    "]\n",
    "\n",
    "ITERATIONS = 5000\n",
    "\n",
    "def log(file, now):\n",
    "    file.write('Recorded at: %s\\n\\n' %now.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
    "    file.write(\"-----------------------------------------------\\n\\n\")\n",
    "    file.write('Noise Ratio : %.1f\\n\\n' %NOISE_RATIO)\n",
    "    file.write('Alpha : %d\\n' %ALPHA)\n",
    "    file.write('Beta  : %d\\n\\n' %BETA)\n",
    "    file.write('Alpha/Beta : %.3f\\n\\n' %(float(ALPHA)/float(BETA)))\n",
    "    file.write('Style layers & weights\\n')\n",
    "    for l in STYLE_LAYERS:\n",
    "        file.write(str(l)+\"\\n\")\n",
    "    file.write(\"\\n\")\n",
    "    file.write('Content layers & weights\\n')\n",
    "    for l in CONTENT_LAYERS:\n",
    "        file.write(str(l)+\"\\n\")\n",
    "    file.write(\"\\n\")\n",
    "    file.write(\"Iteratioln : %d\\n\\n\" %(ITERATIONS))\n",
    "    file.write(\"-----------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loss Function\n",
    "\n",
    "\n",
    "$N_{\\ell}$ : Number of filters at layer $\\ell$  <br>\n",
    "$M_{\\ell}$ : Size of feature map ($width * height$) at layer $\\ell$  <br>\n",
    "$w_{\\ell}$ : Weight (contribution) of layer to each loss (style/content)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\sum{w_{\\ell}}=1$<br><br>\n",
    "\n",
    "<b>[1]</b> Content Loss ($\\mathcal{L}_{content}$)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$F^{\\ell}$ : Activation matrix ($\\in \\mathcal{R}^{N_\\ell \\times M_\\ell}$) at layer $\\ell$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;($F^{\\ell}_{ij}$ is the activation of $i^{th}$ filter at position $j$ in layer $\\ell$) <br><br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\mathcal{L}_{content} = \\frac{1}{2}\\sum_{ij} (F^{\\ell}_{{ij}_{output}} - F^{\\ell}_{{ij}_{input}})^2$<br><br>\n",
    "\n",
    "<b>[2]</b> Style Loss ($\\mathcal{L}_{style}$)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$G^{\\ell}$ : Gram matrix ($\\in \\mathcal{R}^{N_\\ell \\times N_\\ell}$) - correlation of filters at layer $\\ell$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;($G^{\\ell}_{ij} = \\frac{1}{2}\\sum_{k} F^{\\ell}_{{ik}}F^{\\ell}_{{jk}}$)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$E_{\\ell}$ : style loss in layer $\\ell$ <br><br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$E_{\\ell} = \\frac{1}{4N^{2}_{\\ell}M^{2}_{\\ell}}\\sum_{ij} (G^{\\ell}_{{ij}_{output}} - G^{\\ell}_{{ij}_{input}})^2$<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\mathcal{L}_{style} = \\sum_{\\ell} \\mathcal{w}_{\\ell}E_{\\ell}$<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def content_loss_func(sess, model):\n",
    "\n",
    "    def _content_loss(p, x):\n",
    "        N = p.shape[3]\n",
    "        M = p.shape[1] * p.shape[2]\n",
    "        return (1 / 2) * tf.reduce_sum(tf.pow(x - p, 2))\n",
    "    \n",
    "    E = [_content_loss(sess.run(model[layer_name]), model[layer_name]) for layer_name, _ in CONTENT_LAYERS]\n",
    "    W = [w for _, w in CONTENT_LAYERS]\n",
    "    loss = sum([W[l] * E[l] for l in range(len(CONTENT_LAYERS))])\n",
    "    return loss\n",
    "\n",
    "def style_loss_func(sess, model):\n",
    "\n",
    "    def _gram_matrix(F, N, M):\n",
    "        Ft = tf.reshape(F, (M, N))\n",
    "        return tf.matmul(tf.transpose(Ft), Ft)\n",
    "\n",
    "    def _style_loss(a, x):\n",
    "        N = a.shape[3]\n",
    "        M = a.shape[1] * a.shape[2]\n",
    "    \n",
    "        A = _gram_matrix(a, N, M)\n",
    "        G = _gram_matrix(x, N, M)\n",
    "        result = (1 / (4 * N**2 * M**2)) * tf.reduce_sum(tf.pow(G - A, 2))\n",
    "        return result\n",
    "\n",
    "    E = [_style_loss(sess.run(model[layer_name]), model[layer_name]) for layer_name, _ in STYLE_LAYERS]\n",
    "    W = [w for _, w in STYLE_LAYERS]\n",
    "    loss = sum([W[l] * E[l] for l in range(len(STYLE_LAYERS))])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate/Load/Save Image Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_noise_image(content_image, noise_ratio = NOISE_RATIO):\n",
    "    noise_image = np.random.uniform(-20, 20, (1, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS)).astype('float32')\n",
    "    input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "    return input_image\n",
    "\n",
    "def load_image(path):\n",
    "    image = scipy.misc.imread(path, mode='RGB')\n",
    "    image = np.reshape(image, ((1,) + image.shape))\n",
    "    image = image - MEAN_VALUES\n",
    "    return image\n",
    "\n",
    "def save_image(path, image):\n",
    "    image = image + MEAN_VALUES\n",
    "    image = image[0]\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Model\n",
    "\n",
    "<b>Notice</b> : paper use average pooling instead of max pooling<br>\n",
    "<b>Notice</b> : paper use normalized VGG-19 by scaling the weights such that the mean activation of each convolutional filter over images and positions is equal to one. This helps with the image generation and apologise that this was not made clear in the preprint version of the manuscripts.\n",
    "\n",
    "Load VGG-19 Model and parse it.<br>\n",
    "W : weight vector<br>\n",
    "b : bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_vgg_model(path):\n",
    "\n",
    "    vgg = scipy.io.loadmat(path)\n",
    "\n",
    "    vgg_layers = vgg['layers']\n",
    "    \n",
    "    def _weights(layer, expected_layer_name):\n",
    "\n",
    "        W = vgg_layers[0][layer][0][0][2][0][0]\n",
    "        b = vgg_layers[0][layer][0][0][2][0][1]\n",
    "        layer_name = vgg_layers[0][layer][0][0][0][0]\n",
    "        \n",
    "        if expected_layer_name != layer_name:\n",
    "            print(\"Warning : layer %s is not matched\" % expected_layer_name)\n",
    "        \n",
    "        return W, b\n",
    "\n",
    "    def _relu(conv2d_layer):\n",
    "        return tf.nn.relu(conv2d_layer)\n",
    "\n",
    "    def _conv2d(prev_layer, layer, layer_name):\n",
    "        W, b = _weights(layer, layer_name)\n",
    "        W = tf.constant(W)\n",
    "        b = tf.constant(np.reshape(b, (b.size)))\n",
    "        return tf.nn.conv2d(\n",
    "            prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "\n",
    "    def _conv2d_relu(prev_layer, layer, layer_name):\n",
    "        return _relu(_conv2d(prev_layer, layer, layer_name))\n",
    "\n",
    "    def _avgpool(prev_layer):\n",
    "        return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    graph = {}\n",
    "    graph['input']   = tf.Variable(np.zeros((1, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS)), dtype = 'float32')\n",
    "    graph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n",
    "    graph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n",
    "    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
    "    graph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n",
    "    graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n",
    "    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
    "    graph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n",
    "    graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n",
    "    graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n",
    "    graph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n",
    "    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
    "    graph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n",
    "    graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n",
    "    graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n",
    "    graph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n",
    "    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
    "    graph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n",
    "    graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n",
    "    graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n",
    "    graph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n",
    "    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./images/algorithm.png\">\n",
    "\n",
    "Optimization with ADAM (refer : https://arxiv.org/pdf/1412.6980.pdf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    content_image = load_image(CONTENT_IMAGE)\n",
    "    style_image = load_image(STYLE_IMAGE)\n",
    "    input_image = generate_noise_image(content_image)\n",
    "\n",
    "    model = load_vgg_model(VGG_MODEL)\n",
    "\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    sess.run(model['input'].assign(content_image))\n",
    "    content_loss = content_loss_func(sess, model)\n",
    "\n",
    "    sess.run(model['input'].assign(style_image))\n",
    "    style_loss = style_loss_func(sess, model)\n",
    "\n",
    "    total_loss = ALPHA * content_loss + BETA * style_loss\n",
    "\n",
    "\n",
    "    sess.run(model['input'].assign(input_image))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(2.0)\n",
    "    train_step = optimizer.minimize(total_loss)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(model['input'].assign(input_image))\n",
    "\n",
    "    now = datetime.now()\n",
    "    case = \"result/{:.3f}\".format(ALPHA/BETA)+\"_\"+str(ITERATIONS)+\"_\"+now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    if not os.path.exists(\"result\"):\n",
    "        os.mkdir(\"result\")\n",
    "\n",
    "    if not os.path.exists(case):\n",
    "        os.mkdir(case)\n",
    "\n",
    "    if not os.path.exists(case+\"/output\"):\n",
    "        os.mkdir(case+\"/output\")\n",
    "\n",
    "    save_image(case+\"/1.content\"+CONTENT_IMAGE[CONTENT_IMAGE.rfind('.'):], content_image)\n",
    "    save_image(case+\"/2.style\"+STYLE_IMAGE[STYLE_IMAGE.rfind('.'):], style_image)\n",
    "\n",
    "    file = open(case+\"/Log.txt\", \"a\")\n",
    "    log(file, now)\n",
    "\n",
    "    for it in range(ITERATIONS+1):\n",
    "        sess.run(train_step)\n",
    "        save_it = 1\n",
    "\n",
    "        if it<10 :\n",
    "            save_it = 1\n",
    "        elif it<100 :\n",
    "            save_it = 5\n",
    "        elif it<1000 :\n",
    "            save_it = 10\n",
    "        else :\n",
    "            save_it = 100\n",
    "\n",
    "        if it%save_it == 0:\n",
    "            mixed_image = sess.run(model['input'])\n",
    "            file.write('Iteration %d\\n' % (it))\n",
    "            file.write('sum : ' + str(sess.run(tf.reduce_sum(mixed_image))) + \"\\n\")\n",
    "            file.write('cost: ' + str(sess.run(total_loss)) + \"\\n\\n\")\n",
    "\n",
    "            filename = case+'/output/%04d.png' % (it)\n",
    "            save_image(filename, mixed_image)\n",
    "\n",
    "    save_image(case+\"/3.result.png\", mixed_image)\n",
    "    file.close()\n",
    "    sess.close()\n",
    "    return case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional : Make output pngs to gif\n",
    "\n",
    "Need images2gif.py<br>\n",
    "python2 : https://pypi.python.org/pypi/images2gif <br>\n",
    "python3 : https://github.com/isaacgerg/images2gif <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from images2gif import writeGif\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "def makeAnimatedGif(case):\n",
    "\n",
    "    \"\"\"\n",
    "    image files must be sorted\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    imgFiles = glob(case+\"/output/*.png\")\n",
    "    images = [Image.open(fn) for fn in imgFiles]\n",
    "    \n",
    "    global filename\n",
    "    filename = case + \"/4.out.gif\"\n",
    "    writeGif(filename, images, duration=0.2)\n",
    "    print(\"%s has been created at %s.\" % (filename, os.path.realpath(filename)))\n",
    "\n",
    "def start(case):\n",
    "    print(\"Creating animated gif....\")\n",
    "    makeAnimatedGif(case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating animated gif....\n",
      "result/0.001_5000_20170218_044855/4.out.gif has been created at C:\\Users\\79981\\tensorflow\\result\\0.001_5000_20170218_044855\\4.out.gif.\n"
     ]
    }
   ],
   "source": [
    "start(\"result/0.001_5000_20170218_044855\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', 0.2),\n",
    "    ('conv2_1', 0.2),\n",
    "    ('conv3_1', 0.2),\n",
    "    ('conv4_1', 0.2),\n",
    "    ('conv5_1', 0.2),\n",
    "]\n",
    "\n",
    "\n",
    "start(run())\n",
    "\n",
    "\n",
    "ALPHA = 1\n",
    "BETA = 10000\n",
    "\n",
    "\n",
    "start(run())\n",
    "\n",
    "\n",
    "ALPHA = 1\n",
    "BETA = 100\n",
    "\n",
    "\n",
    "start(run())\n",
    "\n",
    "\n",
    "ALPHA = 1\n",
    "BETA = 1000\n",
    "\n",
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', 0.25),\n",
    "    ('conv2_1', 0.25),\n",
    "    ('conv3_1', 0.25),\n",
    "    ('conv4_1', 0.25)\n",
    "]\n",
    "\n",
    "\n",
    "start(run())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
